{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from random import randint\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.layers import Dense, Activation, Embedding, LSTM, Masking\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 80 # cut texts after this number of words (among top max_features most common words)\n",
    "max_features = 200 # Anzahl der WÃ¶rter\n",
    "trainset_size=150\n",
    "testset_size=40\n",
    "lookahead = 5\n",
    "epochs=40\n",
    "RESULTS={\n",
    "        '.': 1,\n",
    "        ',': 2,\n",
    "        '!': 3,\n",
    "        '?': 4,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 114562\n"
     ]
    }
   ],
   "source": [
    "dataset = open(\"dataset.txt\")\n",
    "all_data = dataset.read().split()\n",
    "all_words = list(filter(None, all_data))  # remove empty strings\n",
    "print(\"Total number of words: {}\".format( len(all_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Masking(mask_value=0, input_shape=(maxlen, max_features)))\n",
    "#model.add(Embedding(max_features, 128, input_length=maxlen, dropout=0.2))\n",
    "model.add(LSTM(128, dropout_W=0.2, dropout_U=0.2))  # try using a GRU instead, for fun\n",
    "model.add(Dense(len(RESULTS)+1))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def last_char_to_result(last_char):\n",
    "    i = RESULTS.get(last_char, 0)\n",
    "    result = [0]*(len(RESULTS)+1)\n",
    "    result[i] = 1\n",
    "    return result\n",
    "\n",
    "def clean(string):\n",
    "    return string.replace(\".\", \"\").replace(\",\", \"\").replace(\"!\", \"\").replace(\"?\", \"\")\n",
    "\n",
    "def load_sample(skip= True):\n",
    "    sentence=[] # ['word','word',...]\n",
    "    result=[] # [0,1,0,0,0] #6\n",
    "    offset = randint(0, max(len(all_words), len(all_words) - maxlen - 2))\n",
    "    num_words = randint(2, maxlen)\n",
    "    sentence = all_words[offset:(offset+num_words)]\n",
    "    if sentence == [] or sentence[-1] == '':\n",
    "        return load_sample(skip)\n",
    "    if len(sentence) <= lookahead: \n",
    "        return load_sample(skip)\n",
    "    last_char = sentence[-1-lookahead][-1]\n",
    "    result = last_char_to_result(last_char)\n",
    "    if (skip and (RESULTS.get(last_char, 0) == 0) and (randint(0,100)>30)):\n",
    "        return load_sample(skip)\n",
    "    sentence = list(map(clean, sentence))\n",
    "    return (\" \".join(sentence),result)\n",
    "\n",
    "def transform(sentence):\n",
    "    x = text.one_hot(sentence, max_features, lower=True)\n",
    "    x_new = [ [0 if t != i else 1 for i in range(max_features)] for t in x]\n",
    "    for i in range(maxlen-len(x)):\n",
    "        x_new.append( [0]*200 )\n",
    "    return x_new\n",
    "\n",
    "def create_dataset(size, skip= True):\n",
    "    X=[];y=[]\n",
    "    for iteration in range(0, size):\n",
    "        sentence, result = load_sample(skip)\n",
    "        X.append(transform(sentence)) \n",
    "        y.append(result)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = create_dataset(trainset_size)\n",
    "\n",
    "model.fit(X, y, nb_epoch=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s     \n",
      "Test score: 0.307612738013\n",
      "Test accuracy: 0.825\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = create_dataset(testset_size, False)\n",
    "score, acc = model.evaluate(X_test, y_test)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "satz,r = load_sample()\n",
    "y = model.predict(np.array([transform(satz)]))[-1]\n",
    "\n",
    "inv_results = {v: k for k, v in RESULTS.items()}\n",
    "i=0\n",
    "max_pos = np.argmax(y)\n",
    "for prob in y:\n",
    "    char = inv_results.get(i, ' ')\n",
    "    ok = 'actual' if r[i]==1 else ''\n",
    "    ok = ok + (\" - predicted\" if max_pos == i else '')\n",
    "    print(char + \" = {:10.2f} \".format(prob*100) + (ok))\n",
    "    i = i+1\n",
    "    \n",
    "print(satz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}